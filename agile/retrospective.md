# ğŸ”„ Sprint Retrospective

**Project:** Student Performance Predictor
**Sprint Duration:** 2-Day Hackathon Sprint

---

## âœ… What Went Well

### ğŸŸ¢ 1. Clear Task Division

Each team member took responsibility for a specific part (ML model, backend API, frontend UI, analytics).
This improved speed and reduced overlap.

### ğŸŸ¢ 2. Fast Debugging & Problem Solving

Issues like Python version mismatch, CORS errors, and UI bugs were resolved quickly.
Team handled critical blockers efficiently.

### ğŸŸ¢ 3. Smooth End-to-End Integration

Backend â†’ Frontend â†’ Charts â†’ Faculty dashboard worked almost immediately after connection.
Minimal errors during final testing.

### ğŸŸ¢ 4. Strong UI/UX

The clean, modern dashboard improved the quality of the presentation.
Judges will immediately understand the system.

### ğŸŸ¢ 5. On-Time Deployment

Both Netlify & Render deployments were completed ahead of final submission time.

---

## âš ï¸ What Could Be Improved

### ğŸŸ¡ 1. Backend & ML Planning

Some features (name field automation, database storage) required more planning.
Better upfront design would avoid last-minute rush.

### ğŸŸ¡ 2. UI Consistency

Some screens initially looked inconsistent (faculty layout vs main UI).
More time for polishing would help unify the theme.

### ğŸŸ¡ 3. Testing With More Data

Most CSV tests were synthetic.
Real student datasets could give better performance insights.

### ğŸŸ¡ 4. Time Allocation

Too much time was spent fixing deployment issues.
In the future, deployment should be done earlier in the sprint.

---

## âŒ What Did Not Go Well

* Last-minute design changes slowed down frontend polishing
* Render server shutdown briefly during testing
* Some advanced analytics (trend charts, student names automation) were left incomplete
* Adding database support was not possible within sprint time

These did **not** affect core deliverables but can be included post-hackathon.

---

## ğŸš€ Action Items (For Future Sprints)

### ğŸ”§ Technical

* Add student name as a proper field (UI + CSV + API)
* Add database to store prediction logs
* Add authentication (student & faculty)
* Add trend graphs (year-wise, subject-wise improvements)

### ğŸ¨ UI/UX

* Improve mobile responsiveness further
* Add dark/light theme toggle
* Create a separate admin dashboard

### ğŸ“ˆ ML

* Use a real dataset
* Add explainability (feature importance, SHAP)
* Allow multiple ML models (SVM, XGBoost, ANN) and compare

---

## â­ Final Thought

Despite time pressure, the team delivered a **stable, deployable, user-friendly ML system** that meets all hackathon requirements.
The team collaborated effectively, adapted to challenges, and finished strong.

---
